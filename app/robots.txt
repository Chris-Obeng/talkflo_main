# See https://www.robotstxt.org/robotstxt.html for documentation on how to use the robots.txt file
#
# This file is used to prevent search engine crawlers from accessing certain parts of your website.
#
# By default, we are allowing all crawlers to access all parts of the website.

User-agent: *
Allow: /

# Disallow internal app-only routes
Disallow: /protected/
Disallow: /auth/
Disallow: /api/

Sitemap: https://talkflo.co/sitemap.xml